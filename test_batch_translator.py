import os
import webvtt
import tiktoken
import time
from typing import List, Optional

"""
æ‰¹é‡VTTå­—å¹•ç¿»è¯‘å™¨ - æµ‹è¯•ç‰ˆæœ¬
===============================================
è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ç‰ˆæœ¬ï¼Œä½¿ç”¨æ¨¡æ‹ŸAPIæ¥éªŒè¯æ•´ä¸ªå¤„ç†æµç¨‹
"""

# ==================== é…ç½®åŒº ====================

INPUT_FOLDER = 'output_result'
OUTPUT_FOLDER = 'translated_md_test'
MAX_TOKENS_PER_CHUNK = 2500

# æ¨¡æ‹Ÿç¿»è¯‘æç¤ºè¯ï¼ˆç”¨äºæµ‹è¯•ï¼‰
SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä½é¡¶çº§çš„ç¿»è¯‘å®¶å’Œå†…å®¹ç¼–è¾‘ã€‚
ä½ çš„ä»»åŠ¡æ˜¯ï¼šå°†ç”¨æˆ·æä¾›çš„ä¸­æ–‡è§†é¢‘å­—å¹•ï¼Œæ•´ç†æˆä¸€ç¯‡æµç•…ã€è‡ªç„¶ã€è¿è´¯çš„ç®€ä½“ä¸­æ–‡æ–‡ç« ã€‚

è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹æ ¸å¿ƒåŸåˆ™ï¼š
1. **å…¨æ–‡æ•´ç†ä¸åˆå¹¶**ï¼š
   - å¿…é¡»ä¿ç•™æ‰€æœ‰é‡è¦å†…å®¹ï¼Œä¸èƒ½çœç•¥å…³é”®ä¿¡æ¯ã€‚
   - **å…³é”®æŒ‡ä»¤**ï¼šè¯·æ™ºèƒ½åœ°å°†åŸæ–‡ä¸­è¯­ä¹‰è¿è´¯çš„å¤šè¡ŒçŸ­å¥ï¼Œåˆå¹¶æˆç¬¦åˆä¸­æ–‡é˜…è¯»ä¹ æƒ¯çš„è‡ªç„¶æ®µè½ã€‚

2. **å†…å®¹ä¼˜åŒ–**ï¼š
   - å»é™¤é‡å¤çš„å£è¯­åŒ–è¡¨è¾¾å’Œå¡«å……è¯
   - ä¿®æ­£è¯­æ³•é”™è¯¯ï¼Œä½¿è¡¨è¾¾æ›´åŠ è§„èŒƒ
   - ä¿æŒåŸæ„çš„åŒæ—¶ï¼Œè®©æ–‡ç« æ›´åŠ æµç•…æ˜“è¯»

3. **æ ¼å¼è¦æ±‚**ï¼š
   - ä½¿ç”¨ Markdown æ ¼å¼è¾“å‡º
   - å¯¹å…³é”®è¯è¿›è¡Œ **åŠ ç²—** ä»¥æé«˜å¯è¯»æ€§
   - åˆç†åˆ†æ®µï¼Œç¡®ä¿é€»è¾‘æ¸…æ™°

4. **ç›´æ¥è¾“å‡º**ï¼šè¯·ç›´æ¥å¼€å§‹è¾“å‡ºæœ€ç»ˆæ•´ç†å¥½çš„ä¸­æ–‡æ–‡ç« ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæˆ–æ ‡ç­¾ã€‚
"""

class TestVTTTranslator:
    def __init__(self):
        self.tokenizer = self._get_tokenizer()
        
    def _get_tokenizer(self) -> Optional[any]:
        """è·å–tokenizerç”¨äºæ–‡æœ¬åˆ†ç‰‡"""
        try:
            return tiktoken.get_encoding("cl100k_base")
        except Exception as e:
            print(f"è·å– tokenizer å¤±è´¥: {e}")
            return None
    
    def parse_vtt_file(self, file_path: str) -> Optional[str]:
        """è§£æVTTæ–‡ä»¶ï¼Œæå–æ–‡æœ¬å†…å®¹"""
        try:
            captions = webvtt.read(file_path)
            texts = []
            for caption in captions:
                text = caption.text.strip()
                if text:
                    texts.append(text)
            
            full_text = "\n".join(texts)
            return full_text
        except Exception as e:
            print(f"è§£æVTTæ–‡ä»¶ {os.path.basename(file_path)} æ—¶å‡ºé”™: {e}")
            return None
    
    def split_text_into_chunks(self, text: str) -> List[str]:
        """å°†æ–‡æœ¬åˆ†ç‰‡å¤„ç†ï¼Œé¿å…è¶…è¿‡tokené™åˆ¶"""
        if not self.tokenizer:
            print("Tokenizer ä¸å¯ç”¨ï¼Œå°†å°è¯•ä¸€æ¬¡æ€§å¤„ç†ã€‚")
            return [text]
        
        tokens = self.tokenizer.encode(text)
        if len(tokens) <= MAX_TOKENS_PER_CHUNK:
            return [text]
        
        print(f"æ–‡æœ¬è¿‡é•¿ ({len(tokens)} tokens)ï¼Œæ­£åœ¨åˆ†ç‰‡å¤„ç†...")
        chunks = []
        current_chunk_tokens = []
        
        lines = text.split('\n')
        for line in lines:
            if not line.strip():
                continue
                
            line_tokens = self.tokenizer.encode(line + "\n")
            
            if len(current_chunk_tokens) + len(line_tokens) > MAX_TOKENS_PER_CHUNK:
                if current_chunk_tokens:
                    chunks.append(self.tokenizer.decode(current_chunk_tokens))
                    current_chunk_tokens = []
            
            current_chunk_tokens.extend(line_tokens)
        
        if current_chunk_tokens:
            chunks.append(self.tokenizer.decode(current_chunk_tokens))
        
        print(f"æ–‡æœ¬æˆåŠŸåˆ†æˆäº† {len(chunks)} ä¸ªç‰‡æ®µã€‚")
        return chunks
    
    def mock_api_call(self, text_chunk: str) -> str:
        """æ¨¡æ‹ŸAPIè°ƒç”¨ - ç”¨äºæµ‹è¯•"""
        print("æ¨¡æ‹ŸAPIå¤„ç†ä¸­...")
        time.sleep(0.5)  # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
        
        # ç®€å•çš„æ–‡æœ¬å¤„ç†æ¨¡æ‹Ÿ
        lines = text_chunk.split('\n')
        processed_lines = []
        current_paragraph = []
        
        for line in lines:
            line = line.strip()
            if not line:
                if current_paragraph:
                    processed_lines.append(' '.join(current_paragraph))
                    current_paragraph = []
                continue
            
            current_paragraph.append(line)
            
            # æ¯3-5å¥åˆå¹¶æˆä¸€æ®µ
            if len(current_paragraph) >= 4:
                processed_lines.append(' '.join(current_paragraph))
                current_paragraph = []
        
        # å¤„ç†å‰©ä½™çš„å¥å­
        if current_paragraph:
            processed_lines.append(' '.join(current_paragraph))
        
        # æ·»åŠ ä¸€äº›åŸºæœ¬çš„æ ¼å¼åŒ–
        result = '\n\n'.join(processed_lines)
        
        # æ¨¡æ‹Ÿæ·»åŠ ä¸€äº›å…³é”®è¯åŠ ç²—
        keywords = ['åŠ å¯†è²¨å¹£', 'æ¯”ç‰¹å¹£', 'ä»¥å¤ªå¹£', 'å€å¡Šéˆ', 'äº¤æ˜“', 'æŠ•è³‡', 'BTC', 'ETH', 'ADA']
        for keyword in keywords:
            if keyword in result:
                result = result.replace(keyword, f'**{keyword}**', 1)  # åªæ›¿æ¢ç¬¬ä¸€ä¸ª
        
        return result
    
    def process_file(self, vtt_file_path: str) -> bool:
        """å¤„ç†å•ä¸ªVTTæ–‡ä»¶"""
        filename = os.path.basename(vtt_file_path)
        print(f"\n--- æ­£åœ¨å¤„ç†æ–‡ä»¶: {filename} ---")
        
        # è§£æVTTæ–‡ä»¶
        text_content = self.parse_vtt_file(vtt_file_path)
        if not text_content:
            print(f"æ— æ³•è§£ææ–‡ä»¶: {filename}")
            return False
        
        print(f"âœ“ æå–åˆ° {len(text_content)} ä¸ªå­—ç¬¦çš„æ–‡æœ¬å†…å®¹")
        
        # æ˜¾ç¤ºå‰200ä¸ªå­—ç¬¦ä½œä¸ºé¢„è§ˆ
        preview = text_content[:200].replace('\n', ' ')
        print(f"å†…å®¹é¢„è§ˆ: {preview}...")
        
        # åˆ†ç‰‡å¤„ç†
        chunks = self.split_text_into_chunks(text_content)
        processed_chunks = []
        
        for i, chunk in enumerate(chunks):
            print(f"æ­£åœ¨å¤„ç†ç‰‡æ®µ {i+1}/{len(chunks)}...")
            translated_chunk = self.mock_api_call(chunk)
            processed_chunks.append(translated_chunk)
        
        # åˆå¹¶æ‰€æœ‰å¤„ç†åçš„ç‰‡æ®µ
        final_content = "\n\n---\n\n".join(processed_chunks)
        
        # æ·»åŠ æ–‡ä»¶å¤´ä¿¡æ¯
        header = f"# {os.path.splitext(filename)[0]}\n\n*ç”±æ‰¹é‡VTTå­—å¹•ç¿»è¯‘å™¨å¤„ç†*\n\n---\n\n"
        final_content = header + final_content
        
        # ä¿å­˜ç»“æœ
        output_filename = f"{os.path.splitext(filename)[0]}.md"
        output_path = os.path.join(OUTPUT_FOLDER, output_filename)
        
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(final_content)
            print(f"âœ“ å¤„ç†å®Œæˆï¼æ–‡ä»¶å·²ä¿å­˜è‡³: {output_path}")
            return True
            
        except IOError as e:
            print(f"âœ— ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def batch_process(self):
        """æ‰¹é‡å¤„ç†æ‰€æœ‰VTTæ–‡ä»¶"""
        print("=" * 60)
        print("æ‰¹é‡VTTå­—å¹•ç¿»è¯‘å™¨ - æµ‹è¯•æ¨¡å¼")
        print("=" * 60)
        print(f"è¾“å…¥æ–‡ä»¶å¤¹: {INPUT_FOLDER}")
        print(f"è¾“å‡ºæ–‡ä»¶å¤¹: {OUTPUT_FOLDER}")
        print("ä½¿ç”¨æ¨¡æ‹ŸAPIè¿›è¡Œæµ‹è¯•")
        print("=" * 60)
        
        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶å¤¹
        if not os.path.isdir(INPUT_FOLDER):
            print(f"é”™è¯¯ï¼šè¾“å…¥æ–‡ä»¶å¤¹ä¸å­˜åœ¨ -> {INPUT_FOLDER}")
            return
        
        # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
        if not os.path.isdir(OUTPUT_FOLDER):
            try:
                os.makedirs(OUTPUT_FOLDER)
                print(f"âœ“ å·²åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹: {OUTPUT_FOLDER}")
            except OSError as e:
                print(f"é”™è¯¯ï¼šæ— æ³•åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹ {OUTPUT_FOLDER}ã€‚é”™è¯¯ä¿¡æ¯: {e}")
                return
        
        # è·å–æ‰€æœ‰VTTæ–‡ä»¶
        vtt_files = [f for f in os.listdir(INPUT_FOLDER) if f.lower().endswith('.vtt')]
        
        if not vtt_files:
            print(f"åœ¨ {INPUT_FOLDER} æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°VTTæ–‡ä»¶")
            return
        
        print(f"âœ“ æ‰¾åˆ° {len(vtt_files)} ä¸ªVTTæ–‡ä»¶")
        
        # å¤„ç†ç»Ÿè®¡
        success_count = 0
        failed_count = 0
        
        # é€ä¸ªå¤„ç†æ–‡ä»¶
        for i, filename in enumerate(sorted(vtt_files), 1):
            print(f"\n[è¿›åº¦: {i}/{len(vtt_files)}]")
            vtt_path = os.path.join(INPUT_FOLDER, filename)
            
            if self.process_file(vtt_path):
                success_count += 1
            else:
                failed_count += 1
        
        # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼")
        print(f"âœ… æˆåŠŸå¤„ç†: {success_count} ä¸ªæ–‡ä»¶")
        print(f"âŒ å¤„ç†å¤±è´¥: {failed_count} ä¸ªæ–‡ä»¶")
        print(f"ğŸ“Š æ€»è®¡æ–‡ä»¶: {len(vtt_files)} ä¸ª")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {OUTPUT_FOLDER}")
        print("=" * 60)
        
        # æ˜¾ç¤ºç”Ÿæˆçš„æ–‡ä»¶
        if success_count > 0:
            print("\nç”Ÿæˆçš„æ–‡ä»¶:")
            try:
                output_files = os.listdir(OUTPUT_FOLDER)
                for f in sorted(output_files):
                    if f.endswith('.md'):
                        file_path = os.path.join(OUTPUT_FOLDER, f)
                        file_size = os.path.getsize(file_path)
                        print(f"  ğŸ“„ {f} ({file_size} bytes)")
            except Exception as e:
                print(f"æ— æ³•åˆ—å‡ºè¾“å‡ºæ–‡ä»¶: {e}")

def main():
    """ä¸»ç¨‹åºå…¥å£"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•æ‰¹é‡VTTå­—å¹•ç¿»è¯‘å™¨...")
    
    translator = TestVTTTranslator()
    translator.batch_process()
    
    print("\nğŸ’¡ æµ‹è¯•å®Œæˆï¼å¦‚æœæµ‹è¯•ç»“æœæ»¡æ„ï¼Œå¯ä»¥é…ç½®çœŸå®çš„APIè¿›è¡Œæ­£å¼å¤„ç†ã€‚")

if __name__ == '__main__':
    main()
