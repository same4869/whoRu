"""
Telegramé¢‘é“ç½‘é¡µçˆ¬è™«ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
ä¸éœ€è¦API credentialsï¼Œä½†åŠŸèƒ½æœ‰é™
ä»…é€‚ç”¨äºå…¬å¼€é¢‘é“
"""
import requests
from bs4 import BeautifulSoup
import json
import os
from datetime import datetime
import time
import sys
import io

# ä¿®å¤Windowsä¸­æ–‡ç¼–ç é—®é¢˜
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

class TelegramWebScraper:
    def __init__(self):
        self.base_url = "https://t.me/s/"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'
        }
    
    def scrape_channel(self, channel_username, output_dir='tg/output'):
        """
        çˆ¬å–å…¬å¼€é¢‘é“çš„å†…å®¹ï¼ˆç½‘é¡µç‰ˆï¼‰
        
        å‚æ•°:
            channel_username: é¢‘é“ç”¨æˆ·å
            output_dir: è¾“å‡ºç›®å½•
        """
        # æ¸…ç†é¢‘é“åç§°
        if 'https://t.me/' in channel_username:
            channel_username = channel_username.split('/')[-1]
        if channel_username.startswith('@'):
            channel_username = channel_username[1:]
        
        url = f"{self.base_url}{channel_username}"
        print(f"ğŸ“¡ æ­£åœ¨è®¿é—®: {url}")
        
        try:
            response = requests.get(url, headers=self.headers, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # è·å–é¢‘é“æ ‡é¢˜
            channel_title_elem = soup.find('div', class_='tgme_channel_info_header_title')
            channel_title = channel_title_elem.get_text(strip=True) if channel_title_elem else channel_username
            
            print(f"ğŸ“Œ é¢‘é“åç§°: {channel_title}")
            
            # æŸ¥æ‰¾æ‰€æœ‰æ¶ˆæ¯
            messages = soup.find_all('div', class_='tgme_widget_message_wrap')
            print(f"ğŸ“Š æ‰¾åˆ° {len(messages)} æ¡æ¶ˆæ¯ï¼ˆæœ€è¿‘çš„æ¶ˆæ¯ï¼‰")
            
            messages_data = []
            
            for msg in messages:
                message_div = msg.find('div', class_='tgme_widget_message')
                if not message_div:
                    continue
                
                # æå–æ¶ˆæ¯ID
                msg_link = message_div.get('data-post', '')
                msg_id = msg_link.split('/')[-1] if msg_link else ''
                
                # æå–æ—¥æœŸæ—¶é—´
                time_elem = message_div.find('time')
                msg_date = time_elem.get('datetime', '') if time_elem else ''
                
                # æå–æ–‡æœ¬å†…å®¹
                text_elem = message_div.find('div', class_='tgme_widget_message_text')
                msg_text = text_elem.get_text(strip=True) if text_elem else ''
                
                # æå–æµè§ˆé‡
                views_elem = message_div.find('span', class_='tgme_widget_message_views')
                views = views_elem.get_text(strip=True) if views_elem else '0'
                
                if msg_text:  # åªä¿å­˜æœ‰æ–‡æœ¬çš„æ¶ˆæ¯
                    messages_data.append({
                        'id': msg_id,
                        'date': msg_date,
                        'text': msg_text,
                        'views': views,
                    })
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            os.makedirs(output_dir, exist_ok=True)
            
            # ä¿å­˜ä¸ºJSON
            json_file = os.path.join(output_dir, f'{channel_username}_web_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json')
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'channel': channel_username,
                    'title': channel_title,
                    'scrape_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'message_count': len(messages_data),
                    'messages': messages_data
                }, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ JSONæ–‡ä»¶å·²ä¿å­˜: {json_file}")
            
            # ä¿å­˜ä¸ºMarkdown
            md_file = os.path.join(output_dir, f'{channel_username}_web_{datetime.now().strftime("%Y%m%d_%H%M%S")}.md')
            with open(md_file, 'w', encoding='utf-8') as f:
                f.write(f"# {channel_title}\n\n")
                f.write(f"**é¢‘é“**: @{channel_username}\n\n")
                f.write(f"**çˆ¬å–æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                f.write(f"**æ¶ˆæ¯æ•°é‡**: {len(messages_data)} (ä»…æ˜¾ç¤ºæœ€è¿‘çš„æ¶ˆæ¯)\n\n")
                f.write(f"**è¯´æ˜**: æ­¤æ•°æ®é€šè¿‡ç½‘é¡µçˆ¬å–è·å¾—ï¼Œä»…åŒ…å«æœ€è¿‘çš„å…¬å¼€æ¶ˆæ¯ã€‚å¦‚éœ€å®Œæ•´å†å²è®°å½•ï¼Œè¯·ä½¿ç”¨APIæ–¹å¼ã€‚\n\n")
                f.write("---\n\n")
                
                for msg in reversed(messages_data):
                    f.write(f"## æ¶ˆæ¯ #{msg['id']}\n\n")
                    f.write(f"**æ—¶é—´**: {msg['date']}\n\n")
                    f.write(f"**æµè§ˆé‡**: {msg['views']}\n\n")
                    f.write(f"{msg['text']}\n\n")
                    f.write("---\n\n")
            
            print(f"ğŸ’¾ Markdownæ–‡ä»¶å·²ä¿å­˜: {md_file}")
            print(f"\nâš ï¸  æ³¨æ„: ç½‘é¡µçˆ¬å–åªèƒ½è·å–æœ€è¿‘çš„éƒ¨åˆ†æ¶ˆæ¯ï¼ˆé€šå¸¸20æ¡å·¦å³ï¼‰")
            print(f"    å¦‚éœ€å®Œæ•´å†å²è®°å½•ï¼Œå»ºè®®ä½¿ç”¨APIæ–¹å¼ï¼ˆtg_channel_scraper.pyï¼‰")
            
            return messages_data
            
        except requests.exceptions.RequestException as e:
            print(f"âŒ ç½‘ç»œè¯·æ±‚é”™è¯¯: {str(e)}")
            return None
        except Exception as e:
            print(f"âŒ è§£æé”™è¯¯: {str(e)}")
            return None
    
    def scrape_multiple_channels(self, channel_list, output_dir='tg/output'):
        """æ‰¹é‡çˆ¬å–å¤šä¸ªé¢‘é“"""
        results = {}
        for channel in channel_list:
            print(f"\n{'='*50}")
            result = self.scrape_channel(channel, output_dir)
            results[channel] = result
            time.sleep(3)  # é¿å…è¯·æ±‚è¿‡å¿«
        return results


def main():
    """ä¸»å‡½æ•°ç¤ºä¾‹"""
    scraper = TelegramWebScraper()
    
    # çˆ¬å–å•ä¸ªé¢‘é“
    scraper.scrape_channel('jmhbzsk', output_dir='tg/output')
    
    # æˆ–è€…æ‰¹é‡çˆ¬å–
    # channels = ['jmhbzsk', 'other_channel']
    # scraper.scrape_multiple_channels(channels, output_dir='tg/output')


if __name__ == '__main__':
    main()

