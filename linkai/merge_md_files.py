#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Markdownæ–‡ä»¶åˆå¹¶å·¥å…·
æŒ‰æ—¥æœŸèŒƒå›´åˆå¹¶æ–‡æ¡£ï¼Œæ¯ä¸ªåˆå¹¶æ–‡ä»¶æ§åˆ¶åœ¨1000è¡Œå·¦å³

ä½¿ç”¨æ–¹æ³•ï¼š
python merge_md_files.py           # é¢„è§ˆæ¨¡å¼
python merge_md_files.py -e        # æ‰§è¡Œåˆå¹¶
python merge_md_files.py -l 800    # è‡ªå®šä¹‰è¡Œæ•°é™åˆ¶
"""

import os
import glob
import re
import argparse
from datetime import datetime, timedelta
from pathlib import Path
import yaml

# é…ç½®
MD_FOLDER = r'D:\xwang\git_work_wx\whoRu\linkai\wechat_xiaotudachengzi_result'
MERGED_FOLDER = r'D:\xwang\git_work_wx\whoRu\linkai\wechat_xiaotudachengzi_result_merged'
DEFAULT_MAX_LINES = 3000

def extract_date_from_filename(filename):
    """ä»æ–‡ä»¶åä¸­æå–æ—¥æœŸ"""
    # åŒ¹é… YYYY-MM-DD æ ¼å¼
    date_match = re.search(r'(\d{4})-(\d{2})-(\d{2})', filename)
    if date_match:
        year, month, day = date_match.groups()
        try:
            return datetime(int(year), int(month), int(day))
        except ValueError:
            return None
    return None

def count_lines_in_file(file_path):
    """ç»Ÿè®¡æ–‡ä»¶è¡Œæ•°"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return sum(1 for line in f)
    except Exception:
        return 0

def read_md_file(file_path):
    """è¯»å–Markdownæ–‡ä»¶å†…å®¹"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        return content
    except Exception as e:
        print(f"  âŒ è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return None

def extract_frontmatter_and_content(content):
    """åˆ†ç¦»YAMLå‰ç½®æ•°æ®å’Œæ­£æ–‡å†…å®¹"""
    if content.startswith('---'):
        parts = content.split('---', 2)
        if len(parts) >= 3:
            frontmatter = parts[1].strip()
            main_content = parts[2].strip()
            return frontmatter, main_content
    
    return None, content

def analyze_files():
    """åˆ†ææ‰€æœ‰Markdownæ–‡ä»¶"""
    print("=== æ–‡ä»¶åˆ†æ ===")
    
    # è·å–æ‰€æœ‰MDæ–‡ä»¶
    md_files = glob.glob(os.path.join(MD_FOLDER, "*.md"))
    print(f"æ‰¾åˆ° {len(md_files)} ä¸ªMarkdownæ–‡ä»¶")
    
    file_info = []
    total_lines = 0
    
    for md_file in md_files:
        filename = os.path.basename(md_file)
        date = extract_date_from_filename(filename)
        lines = count_lines_in_file(md_file)
        
        file_info.append({
            'path': md_file,
            'filename': filename,
            'date': date,
            'lines': lines
        })
        
        total_lines += lines
    
    # æŒ‰æ—¥æœŸæ’åº
    file_info.sort(key=lambda x: x['date'] if x['date'] else datetime.min)
    
    print(f"æ€»è¡Œæ•°: {total_lines}")
    print(f"å¹³å‡æ¯æ–‡ä»¶: {total_lines // len(file_info) if file_info else 0} è¡Œ")
    
    # æ˜¾ç¤ºæ—¥æœŸèŒƒå›´
    dated_files = [f for f in file_info if f['date']]
    if dated_files:
        earliest = min(f['date'] for f in dated_files)
        latest = max(f['date'] for f in dated_files)
        print(f"æ—¥æœŸèŒƒå›´: {earliest.strftime('%Y-%m-%d')} åˆ° {latest.strftime('%Y-%m-%d')}")
        print(f"æœ‰æ—¥æœŸçš„æ–‡ä»¶: {len(dated_files)} ä¸ª")
        print(f"æ— æ—¥æœŸçš„æ–‡ä»¶: {len(file_info) - len(dated_files)} ä¸ª")
    
    return file_info, total_lines

def group_files_by_lines(file_info, max_lines_per_group):
    """æŒ‰è¡Œæ•°é™åˆ¶åˆ†ç»„æ–‡ä»¶"""
    groups = []
    current_group = []
    current_lines = 0
    
    for file_data in file_info:
        # å¦‚æœæ·»åŠ è¿™ä¸ªæ–‡ä»¶ä¼šè¶…è¿‡é™åˆ¶ï¼Œä¸”å½“å‰ç»„ä¸ä¸ºç©ºï¼Œåˆ™å¼€å§‹æ–°ç»„
        if current_lines + file_data['lines'] > max_lines_per_group and current_group:
            groups.append(current_group)
            current_group = [file_data]
            current_lines = file_data['lines']
        else:
            current_group.append(file_data)
            current_lines += file_data['lines']
    
    # æ·»åŠ æœ€åä¸€ç»„
    if current_group:
        groups.append(current_group)
    
    return groups

def generate_group_filename(group, group_index):
    """ç”Ÿæˆåˆå¹¶æ–‡ä»¶çš„æ–‡ä»¶å"""
    dated_files = [f for f in group if f['date']]
    
    if dated_files:
        # æŒ‰æ—¥æœŸæ’åº
        dated_files.sort(key=lambda x: x['date'])
        start_date = dated_files[0]['date']
        end_date = dated_files[-1]['date']
        
        if start_date == end_date:
            # åŒä¸€å¤©çš„æ–‡ä»¶
            return f"åˆé›†_{start_date.strftime('%Y-%m-%d')}_{len(group)}ç¯‡.md"
        else:
            # æ—¥æœŸèŒƒå›´
            return f"åˆé›†_{start_date.strftime('%Y-%m-%d')}_è‡³_{end_date.strftime('%Y-%m-%d')}_{len(group)}ç¯‡.md"
    else:
        # æ— æ—¥æœŸæ–‡ä»¶
        return f"åˆé›†_æ— æ—¥æœŸæ–‡ä»¶_{group_index+1}_{len(group)}ç¯‡.md"

def create_merged_content(group, group_filename):
    """åˆ›å»ºåˆå¹¶æ–‡ä»¶çš„å†…å®¹"""
    # ç»Ÿè®¡ä¿¡æ¯
    total_files = len(group)
    total_lines = sum(f['lines'] for f in group)
    dated_files = [f for f in group if f['date']]
    
    # åˆ›å»ºæ–‡ä»¶å¤´éƒ¨
    header = f"""# {os.path.splitext(group_filename)[0]}

**åˆå¹¶ä¿¡æ¯:**
- æ–‡ä»¶æ•°é‡: {total_files} ç¯‡
- æ€»è¡Œæ•°: {total_lines} è¡Œ
- åˆå¹¶æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
    
    if dated_files:
        dated_files.sort(key=lambda x: x['date'])
        start_date = dated_files[0]['date']
        end_date = dated_files[-1]['date']
        header += f"- æ—¥æœŸèŒƒå›´: {start_date.strftime('%Y-%m-%d')} è‡³ {end_date.strftime('%Y-%m-%d')}\n"
    
    header += f"""
---

## ç›®å½•

"""
    
    # åˆ›å»ºç›®å½•
    for i, file_data in enumerate(group, 1):
        title = os.path.splitext(file_data['filename'])[0]
        date_str = file_data['date'].strftime('%Y-%m-%d') if file_data['date'] else 'æœªçŸ¥æ—¥æœŸ'
        header += f"{i}. [{title}](#{i}-{title.replace(' ', '-').replace('#', '').replace('?', '').replace('!', '')}) ({date_str}, {file_data['lines']}è¡Œ)\n"
    
    header += "\n---\n\n"
    
    # åˆå¹¶æ–‡ä»¶å†…å®¹
    merged_content = header
    
    for i, file_data in enumerate(group, 1):
        print(f"    åˆå¹¶: {file_data['filename']}")
        
        content = read_md_file(file_data['path'])
        if not content:
            continue
        
        # åˆ†ç¦»å‰ç½®æ•°æ®å’Œæ­£æ–‡
        frontmatter, main_content = extract_frontmatter_and_content(content)
        
        # æ·»åŠ æ–‡ä»¶åˆ†éš”ç¬¦å’Œæ ‡é¢˜
        merged_content += f"\n\n## {i}. {os.path.splitext(file_data['filename'])[0]}\n\n"
        
        # å¦‚æœæœ‰å‰ç½®æ•°æ®ï¼Œæ·»åŠ ä¸ºä¿¡æ¯æ¡†
        if frontmatter:
            try:
                fm_data = yaml.safe_load(frontmatter)
                if isinstance(fm_data, dict):
                    merged_content += "**æ–‡ç« ä¿¡æ¯:**\n"
                    for key, value in fm_data.items():
                        if key in ['title', 'publish_date', 'topics', 'word_count']:
                            merged_content += f"- {key}: {value}\n"
                    merged_content += "\n"
            except:
                pass
        
        # æ·»åŠ æ­£æ–‡å†…å®¹
        merged_content += main_content
        merged_content += "\n\n---\n"
    
    return merged_content

def merge_files(file_info, max_lines_per_group, dry_run=True):
    """æ‰§è¡Œæ–‡ä»¶åˆå¹¶"""
    print(f"\n=== {'é¢„è§ˆ' if dry_run else 'æ‰§è¡Œ'}åˆå¹¶æ“ä½œ ===")
    print(f"æœ€å¤§è¡Œæ•°é™åˆ¶: {max_lines_per_group}")
    
    # æŒ‰è¡Œæ•°åˆ†ç»„
    groups = group_files_by_lines(file_info, max_lines_per_group)
    print(f"å°†åˆ†ä¸º {len(groups)} ä¸ªåˆå¹¶æ–‡ä»¶")
    
    if not dry_run:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(MERGED_FOLDER, exist_ok=True)
    
    for i, group in enumerate(groups):
        group_lines = sum(f['lines'] for f in group)
        group_filename = generate_group_filename(group, i)
        
        print(f"\nğŸ“ åˆå¹¶æ–‡ä»¶ {i+1}/{len(groups)}: {group_filename}")
        print(f"   åŒ…å« {len(group)} ä¸ªæ–‡ä»¶ï¼Œå…± {group_lines} è¡Œ")
        
        if dry_run:
            # é¢„è§ˆæ¨¡å¼ï¼šåªæ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
            for file_data in group[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                date_str = file_data['date'].strftime('%Y-%m-%d') if file_data['date'] else 'æ— æ—¥æœŸ'
                print(f"   - {file_data['filename'][:50]}... ({date_str}, {file_data['lines']}è¡Œ)")
            if len(group) > 5:
                print(f"   ... è¿˜æœ‰ {len(group) - 5} ä¸ªæ–‡ä»¶")
        else:
            # æ‰§è¡Œæ¨¡å¼ï¼šå®é™…åˆå¹¶
            try:
                merged_content = create_merged_content(group, group_filename)
                output_path = os.path.join(MERGED_FOLDER, group_filename)
                
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write(merged_content)
                
                actual_lines = len(merged_content.split('\n'))
                print(f"   âœ… æˆåŠŸåˆ›å»º: {output_path}")
                print(f"   ğŸ“„ å®é™…è¡Œæ•°: {actual_lines}")
                
            except Exception as e:
                print(f"   âŒ åˆå¹¶å¤±è´¥: {e}")
    
    if not dry_run:
        print(f"\nğŸ‰ åˆå¹¶å®Œæˆï¼")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {MERGED_FOLDER}")
        print(f"ğŸ“Š ç”Ÿæˆ {len(groups)} ä¸ªåˆå¹¶æ–‡ä»¶")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Markdownæ–‡ä»¶åˆå¹¶å·¥å…·')
    parser.add_argument('-e', '--execute', action='store_true', 
                       help='æ‰§è¡Œåˆå¹¶ï¼ˆé»˜è®¤ä¸ºé¢„è§ˆæ¨¡å¼ï¼‰')
    parser.add_argument('-l', '--lines', type=int, default=DEFAULT_MAX_LINES,
                       help=f'æ¯ä¸ªåˆå¹¶æ–‡ä»¶çš„æœ€å¤§è¡Œæ•°ï¼ˆé»˜è®¤{DEFAULT_MAX_LINES}ï¼‰')
    
    args = parser.parse_args()
    
    print("=== Markdownæ–‡ä»¶åˆå¹¶å·¥å…· ===")
    print(f"æ¨¡å¼: {'æ‰§è¡Œ' if args.execute else 'é¢„è§ˆ'}")
    print(f"è¾“å…¥ç›®å½•: {MD_FOLDER}")
    print(f"è¾“å‡ºç›®å½•: {MERGED_FOLDER}")
    print("=" * 50)
    
    # åˆ†ææ–‡ä»¶
    file_info, total_lines = analyze_files()
    
    if not file_info:
        print("\nâŒ æ²¡æœ‰æ‰¾åˆ°Markdownæ–‡ä»¶ã€‚")
        return
    
    # é¢„ä¼°åˆå¹¶åçš„æ–‡ä»¶æ•°
    estimated_groups = (total_lines + args.lines - 1) // args.lines
    print(f"\nğŸ“Š é¢„ä¼°å°†ç”Ÿæˆ {estimated_groups} ä¸ªåˆå¹¶æ–‡ä»¶")
    
    # æ‰§è¡Œåˆå¹¶
    merge_files(file_info, args.lines, dry_run=not args.execute)
    
    if not args.execute:
        print(f"\nğŸ’¡ å¦‚éœ€æ‰§è¡Œåˆå¹¶ï¼Œè¯·è¿è¡Œ: python merge_md_files.py -e")
        print(f"ğŸ’¡ è‡ªå®šä¹‰è¡Œæ•°é™åˆ¶: python merge_md_files.py -e -l 800")

if __name__ == "__main__":
    main()
