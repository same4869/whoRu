#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
VTTåˆ°Markdownçš„æ‰¹é‡å¤„ç†å™¨
æ”¯æŒæŒ‡å®šå¤„ç†æ•°é‡ï¼š0è¡¨ç¤ºå…¨éƒ¨å¤„ç†ï¼Œå…¶ä»–æ•°å­—è¡¨ç¤ºå¤„ç†å‰Nä¸ªæ–‡ä»¶

ä½¿ç”¨æ–¹æ³•ï¼š
python batch_vtt_to_md.py 5    # å¤„ç†å‰5ä¸ªæ–‡ä»¶
python batch_vtt_to_md.py 0    # å¤„ç†æ‰€æœ‰æ–‡ä»¶
python batch_vtt_to_md.py      # é»˜è®¤å¤„ç†æ‰€æœ‰æ–‡ä»¶
"""

import os
import sys
import glob
import requests
import json
import time
import re
from pathlib import Path
from datetime import datetime
import argparse

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥åŸæœ‰çš„è§£æå‡½æ•°
sys.path.append(str(Path(__file__).parent.parent))
from call_ai_translate_vtt_to_md import parse_vtt_file

# LinkAI API é…ç½®
API_KEY = "Link_vMAvrW4rezbFYKimorUYy7rJeFOjh3mDNBQu8QrFRm"
BASE_URL = "https://api.link-ai.tech/v1"
CHAT_URL = f"{BASE_URL}/chat/completions"

# æ–‡ä»¶è·¯å¾„é…ç½®
VTT_FOLDER = r'D:\xwang\git_work_wx\whoRu\output_result'
MD_FOLDER = r'D:\xwang\git_work_wx\whoRu\output_result_md_linkai'

# å¤„ç†é…ç½®
BATCH_SIZE = 5  # æ¯æ‰¹å¤„ç†çš„æ–‡ä»¶æ•°é‡
DELAY_BETWEEN_REQUESTS = 1  # è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
BATCH_DELAY = 3  # æ‰¹æ¬¡é—´éš”ï¼ˆç§’ï¼‰

# ç³»ç»Ÿæç¤ºè¯
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å†…å®¹ç¼–è¾‘å’Œç¿»è¯‘ä¸“å®¶ã€‚è¯·å°†ç”¨æˆ·æä¾›çš„ç¹ä½“ä¸­æ–‡è§†é¢‘å­—å¹•è½¬æ¢ä¸ºæµç•…ã€è‡ªç„¶çš„ç®€ä½“ä¸­æ–‡æ–‡ç« ã€‚

è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹è¦æ±‚ï¼š
1. **å®Œæ•´è½¬æ¢**ï¼šå°†æ‰€æœ‰ç¹ä½“ä¸­æ–‡è½¬æ¢ä¸ºç®€ä½“ä¸­æ–‡ï¼Œä¸é—æ¼ä»»ä½•å†…å®¹
2. **æ™ºèƒ½åˆ†æ®µ**ï¼šå°†å£è¯­åŒ–çš„çŸ­å¥åˆå¹¶æˆè‡ªç„¶çš„æ®µè½ï¼Œæ”¹å–„å¯è¯»æ€§
3. **ä¿æŒåŸæ„**ï¼šä¿æŒåŸå§‹å†…å®¹çš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§ï¼Œä¸æ·»åŠ æˆ–åˆ é™¤ä¿¡æ¯
4. **æ ¼å¼ä¼˜åŒ–**ï¼š
   - ä½¿ç”¨åˆé€‚çš„æ ‡é¢˜å’Œæ®µè½ç»“æ„
   - æ·»åŠ å¿…è¦çš„æ ‡ç‚¹ç¬¦å·
   - å»é™¤å£è¯­åŒ–çš„å†—ä½™è¯æ±‡ï¼ˆå¦‚"è¿™ä¸ª"ã€"é‚£ä¸ª"ç­‰è¿‡åº¦ä½¿ç”¨ï¼‰
5. **å†…å®¹ç»“æ„**ï¼š
   - å¼€å¤´éƒ¨åˆ†ï¼šæ¬¢è¿è¯­å’ŒèŠ‚ç›®ä»‹ç»
   - ä¸»è¦å†…å®¹ï¼šæŒ‰é€»è¾‘åˆ†æ®µç»„ç»‡
   - ç»“å°¾éƒ¨åˆ†ï¼šæ€»ç»“å’Œäº’åŠ¨æé†’

ç›´æ¥è¾“å‡ºæ•´ç†åçš„æ–‡ç« å†…å®¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–æ ‡è®°ã€‚"""

def call_linkai_api(messages):
    """è°ƒç”¨LinkAI API"""
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {API_KEY}"
    }
    
    body = {
        "messages": messages,
        "stream": False,
        "temperature": 0.3
    }
    
    try:
        response = requests.post(CHAT_URL, json=body, headers=headers, timeout=60)
        
        if response.status_code == 200:
            result = response.json()
            if 'choices' in result and len(result['choices']) > 0:
                return result['choices'][0]['message']['content']
            else:
                print(f"APIå“åº”æ ¼å¼å¼‚å¸¸: {result}")
                return None
        else:
            print(f"APIè°ƒç”¨å¤±è´¥: {response.status_code}")
            print(f"é”™è¯¯ä¿¡æ¯: {response.text}")
            return None
            
    except Exception as e:
        print(f"APIè°ƒç”¨å¼‚å¸¸: {e}")
        return None

def process_text_with_ai(text, title, publish_date):
    """ä½¿ç”¨AIå¤„ç†æ–‡æœ¬ï¼Œè½¬æ¢ä¸ºé«˜è´¨é‡çš„ç®€ä½“ä¸­æ–‡æ–‡ç« """
    user_prompt = f"""è¯·å°†ä»¥ä¸‹è§†é¢‘å­—å¹•å†…å®¹è½¬æ¢ä¸ºé«˜è´¨é‡çš„ç®€ä½“ä¸­æ–‡æ–‡ç« ï¼š

æ ‡é¢˜ï¼š{title}
å‘å¸ƒæ—¶é—´ï¼š{publish_date}

å­—å¹•å†…å®¹ï¼š
{text}

è¯·æŒ‰ç…§è¦æ±‚è¾“å‡ºæ•´ç†åçš„æ–‡ç« å†…å®¹ã€‚"""

    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": user_prompt}
    ]
    
    return call_linkai_api(messages)

def extract_key_topics(title, content):
    """æå–å…³é”®ä¸»é¢˜"""
    topics = []
    
    # åŠ å¯†è´§å¸ç›¸å…³
    crypto_keywords = {
        'æ¯”ç‰¹å¸': ['æ¯”ç‰¹å¸', 'BTC', 'Bitcoin'],
        'ä»¥å¤ªåŠ': ['ä»¥å¤ªåŠ', 'ä»¥å¤ªå¸', 'ETH', 'Ethereum'], 
        'çˆ±è¾¾å¸': ['çˆ±è¾¾å¸', 'æ„›é”å¸', 'ADA', 'Cardano'],
        'ç‹—ç‹—å¸': ['ç‹—ç‹—å¸', 'DOGE', 'Dogecoin'],
        'XRP': ['XRP', 'Ripple'],
        'Solana': ['Solana', 'SOL']
    }
    
    for topic, keywords in crypto_keywords.items():
        if any(keyword.lower() in title.lower() or keyword.lower() in content.lower() 
               for keyword in keywords):
            topics.append(topic)
    
    # æŠ•èµ„ç›¸å…³
    investment_keywords = ['æŠ•èµ„', 'ä¹°å…¥', 'å–å‡º', 'æŒæœ‰', 'DCA', 'å®šæŠ•', 'ç­–ç•¥']
    if any(keyword in content for keyword in investment_keywords):
        topics.append('æŠ•èµ„ç­–ç•¥')
    
    # å¸‚åœºåˆ†æ
    market_keywords = ['ç‰›å¸‚', 'ç†Šå¸‚', 'è¡Œæƒ…', 'èµ°åŠ¿', 'åˆ†æ', 'é¢„æµ‹', 'å¸‚åœº']
    if any(keyword in content for keyword in market_keywords):
        topics.append('å¸‚åœºåˆ†æ')
    
    return topics if topics else ['åŠ å¯†è´§å¸']

def process_single_vtt_file(vtt_file_path):
    """å¤„ç†å•ä¸ªVTTæ–‡ä»¶"""
    try:
        filename = os.path.basename(vtt_file_path)
        print(f"ğŸ“ å¤„ç†: {filename}")
        
        # è§£æVTTæ–‡ä»¶
        result = parse_vtt_file(vtt_file_path)
        if not result or not result[0]:
            print(f"  âŒ VTTè§£æå¤±è´¥")
            return False
        
        text, timestamp_info = result
        
        # è·å–åŸºæœ¬ä¿¡æ¯
        title = timestamp_info.get('title', 'æœªçŸ¥æ ‡é¢˜') if timestamp_info else os.path.splitext(filename)[0]
        publish_date = timestamp_info.get('publish_date', 'æœªçŸ¥æ—¥æœŸ') if timestamp_info else 'æœªçŸ¥æ—¥æœŸ'
        
        # ä½¿ç”¨AIå¤„ç†å†…å®¹
        processed_content = process_text_with_ai(text, title, publish_date)
        
        if not processed_content:
            print(f"  âŒ AIå¤„ç†å¤±è´¥")
            return False
        
        # æå–ä¸»é¢˜
        topics = extract_key_topics(title, processed_content)
        
        # ç”Ÿæˆæœ€ç»ˆçš„MDå†…å®¹
        md_content = f"""---
title: {title}
publish_date: {publish_date}
topics: {', '.join(topics)}
word_count: {len(processed_content)}
processed_by: LinkAI
processed_at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
---

# {title}

**å‘å¸ƒæ—¶é—´**: {publish_date}  
**ä¸»è¦è¯é¢˜**: {', '.join(topics)}

---

{processed_content}

---

*æœ¬æ–‡ç”±LinkAIæ™ºèƒ½åŠ©æ‰‹æ•´ç†å‘å¸ƒï¼Œå†…å®¹ä»…ä¾›å‚è€ƒ*
"""
        
        # ä¿å­˜MDæ–‡ä»¶
        md_filename = f"{os.path.splitext(filename)[0]}.md"
        md_file_path = os.path.join(MD_FOLDER, md_filename)
        
        with open(md_file_path, 'w', encoding='utf-8') as f:
            f.write(md_content)
        
        print(f"  âœ… å®Œæˆ: {len(processed_content)}å­—ç¬¦")
        return True
        
    except Exception as e:
        print(f"  âŒ å¤„ç†å‡ºé”™: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='VTTåˆ°Markdownæ‰¹é‡å¤„ç†å™¨')
    parser.add_argument('count', type=int, nargs='?', default=0, 
                       help='å¤„ç†æ–‡ä»¶æ•°é‡ï¼š0è¡¨ç¤ºå…¨éƒ¨ï¼Œå…¶ä»–æ•°å­—è¡¨ç¤ºå‰Nä¸ªæ–‡ä»¶')
    
    args = parser.parse_args()
    process_count = args.count
    
    start_time = datetime.now()
    print("=== VTTåˆ°Markdownæ‰¹é‡å¤„ç†å™¨ ===")
    print(f"å¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"è¾“å…¥ç›®å½•: {VTT_FOLDER}")
    print(f"è¾“å‡ºç›®å½•: {MD_FOLDER}")
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(MD_FOLDER, exist_ok=True)
    
    # è·å–æ‰€æœ‰VTTæ–‡ä»¶
    vtt_files = glob.glob(os.path.join(VTT_FOLDER, "*.vtt"))
    print(f"æ‰¾åˆ° {len(vtt_files)} ä¸ªVTTæ–‡ä»¶")
    
    # æ£€æŸ¥å·²å¤„ç†çš„æ–‡ä»¶
    existing_md_files = set()
    if os.path.exists(MD_FOLDER):
        existing_md_files = set(os.path.splitext(f)[0] for f in os.listdir(MD_FOLDER) if f.endswith('.md'))
    
    # è¿‡æ»¤å‡ºæœªå¤„ç†çš„æ–‡ä»¶
    unprocessed_files = []
    for vtt_file in vtt_files:
        base_name = os.path.splitext(os.path.basename(vtt_file))[0]
        if base_name not in existing_md_files:
            unprocessed_files.append(vtt_file)
    
    print(f"éœ€è¦å¤„ç† {len(unprocessed_files)} ä¸ªæ–°æ–‡ä»¶")
    
    if not unprocessed_files:
        print("âœ… æ‰€æœ‰æ–‡ä»¶éƒ½å·²å¤„ç†å®Œæˆï¼")
        return
    
    # æ ¹æ®å‚æ•°ç¡®å®šå¤„ç†çš„æ–‡ä»¶
    if process_count == 0:
        files_to_process = unprocessed_files
        print(f"ğŸš€ å…¨é‡å¤„ç†æ¨¡å¼ï¼šå¤„ç†æ‰€æœ‰ {len(files_to_process)} ä¸ªæ–‡ä»¶")
    else:
        files_to_process = unprocessed_files[:process_count]
        print(f"ğŸ¯ é™é‡å¤„ç†æ¨¡å¼ï¼šå¤„ç†å‰ {len(files_to_process)} ä¸ªæ–‡ä»¶")
    
    # é¢„ä¼°æ—¶é—´
    estimated_time = len(files_to_process) * 20 / 60
    print(f"é¢„ä¼°å¤„ç†æ—¶é—´ï¼šçº¦ {estimated_time:.1f} åˆ†é’Ÿ")
    print(f"APIè°ƒç”¨æ¬¡æ•°ï¼š{len(files_to_process)} æ¬¡")
    
    # å¼€å§‹å¤„ç†
    print(f"\nğŸš€ å¼€å§‹å¤„ç†...")
    
    success_count = 0
    total_files = len(files_to_process)
    
    for i in range(0, total_files, BATCH_SIZE):
        batch_files = files_to_process[i:i+BATCH_SIZE]
        batch_num = i // BATCH_SIZE + 1
        total_batches = (total_files + BATCH_SIZE - 1) // BATCH_SIZE
        
        print(f"\nğŸ”„ æ‰¹æ¬¡ {batch_num}/{total_batches} (æ–‡ä»¶ {i+1}-{min(i+BATCH_SIZE, total_files)})")
        
        for j, vtt_file in enumerate(batch_files):
            if process_single_vtt_file(vtt_file):
                success_count += 1
            
            # è¯·æ±‚é—´éš”
            if j < len(batch_files) - 1:
                time.sleep(DELAY_BETWEEN_REQUESTS)
        
        # æ˜¾ç¤ºè¿›åº¦
        progress = (i + len(batch_files)) / total_files * 100
        elapsed_time = (datetime.now() - start_time).total_seconds() / 60
        print(f"  ğŸ“Š è¿›åº¦: {progress:.1f}% ({i + len(batch_files)}/{total_files}) | ç”¨æ—¶: {elapsed_time:.1f}åˆ†é’Ÿ")
        
        # æ‰¹æ¬¡é—´éš”
        if i + BATCH_SIZE < total_files:
            print(f"  ğŸ’¤ ä¼‘æ¯ {BATCH_DELAY} ç§’...")
            time.sleep(BATCH_DELAY)
    
    end_time = datetime.now()
    total_time = (end_time - start_time).total_seconds() / 60
    
    print(f"\n=== å¤„ç†å®Œæˆ ===")
    print(f"âœ… æˆåŠŸå¤„ç†: {success_count} ä¸ªæ–‡ä»¶")
    print(f"âŒ å¤„ç†å¤±è´¥: {total_files - success_count} ä¸ªæ–‡ä»¶")
    print(f"â±ï¸ æ€»ç”¨æ—¶: {total_time:.1f} åˆ†é’Ÿ")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {MD_FOLDER}")
    print(f"ç»“æŸæ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == "__main__":
    main()
