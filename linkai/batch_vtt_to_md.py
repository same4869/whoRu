#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
VTTåˆ°Markdownçš„é€šç”¨æ‰¹é‡å¤„ç†å™¨
æ”¯æŒå¤„ç†å„ç§ä¸»é¢˜çš„è§†é¢‘å­—å¹•æ–‡ä»¶ï¼Œè‡ªåŠ¨è½¬æ¢ä¸ºé«˜è´¨é‡çš„ç®€ä½“ä¸­æ–‡æ–‡ç« 

åŠŸèƒ½ç‰¹ç‚¹ï¼š
- é€šç”¨ä¸»é¢˜è¯†åˆ«ï¼šæ”¯æŒç§‘æŠ€ã€æ•™è‚²ã€ç”Ÿæ´»ã€å•†ä¸šã€æŠ•èµ„ç†è´¢ã€èŒåœºã€æ–‡åŒ–ã€å¥åº·åŒ»ç–—ã€æ–°é—»æ—¶äº‹ç­‰9å¤§åˆ†ç±»
- æ™ºèƒ½å†…å®¹åˆ†æï¼šæ ¹æ®å†…å®¹ç‰¹å¾è‡ªåŠ¨åˆ†ç±»ï¼ˆæ•™ç¨‹æŒ‡å—ã€ç»éªŒåˆ†äº«ã€è¯„æµ‹æ¨èç­‰ï¼‰
- æ™ºèƒ½APIå¯†é’¥ç®¡ç†ï¼šè‡ªåŠ¨ä»api_keys.txtè¯»å–å¯†é’¥ï¼Œç§¯åˆ†ä¸è¶³æ—¶è‡ªåŠ¨åˆ‡æ¢
- æ™ºèƒ½é‡è¯•æœºåˆ¶ï¼šAPIè¶…æ—¶æˆ–è¿æ¥å¤±è´¥æ—¶è‡ªåŠ¨é‡è¯•ï¼Œ406é”™è¯¯è‡ªåŠ¨åˆ‡æ¢å¯†é’¥
- è¯¦ç»†é”™è¯¯ç»Ÿè®¡ï¼šè®°å½•å„ç§é”™è¯¯ç±»å‹å’Œé‡è¯•æ¬¡æ•°
- å¢å¼ºçš„é”™è¯¯å¤„ç†ï¼šåŒºåˆ†è¶…æ—¶ã€è¿æ¥é”™è¯¯ã€ç§¯åˆ†ä¸è¶³ç­‰ä¸åŒé—®é¢˜

ä½¿ç”¨æ–¹æ³•ï¼š
python batch_vtt_to_md.py 5    # å¤„ç†å‰5ä¸ªæ–‡ä»¶
python batch_vtt_to_md.py 0    # å¤„ç†æ‰€æœ‰æ–‡ä»¶
python batch_vtt_to_md.py      # é»˜è®¤å¤„ç†æ‰€æœ‰æ–‡ä»¶

é…ç½®å‚æ•°ï¼š
- æœ€å¤§é‡è¯•æ¬¡æ•°ï¼š3æ¬¡
- é‡è¯•é—´éš”ï¼š5ç§’
- APIè¶…æ—¶æ—¶é—´ï¼š120ç§’
- ä¸»é¢˜æ ‡ç­¾æ•°é‡ï¼šæœ€å¤š3ä¸ª
"""

import os
import sys
import glob
import requests
import json
import time
import re
from pathlib import Path
from datetime import datetime
import argparse

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥åŸæœ‰çš„è§£æå‡½æ•°
sys.path.append(str(Path(__file__).parent.parent))
from call_ai_translate_vtt_to_md import parse_vtt_file

# LinkAI API é…ç½®
BASE_URL = "https://api.link-ai.tech/v1"
CHAT_URL = f"{BASE_URL}/chat/completions"

# APIå¯†é’¥ç®¡ç†
API_KEYS_FILE = "api_keys.txt"
DEPRECATED_KEYS_FILE = "deprecated_apikeys.txt"
current_api_key = None

# æ–‡ä»¶è·¯å¾„é…ç½®
VTT_FOLDER = r'../output_result'
MD_FOLDER = r'../output_result_md_linkai'

# å¤„ç†é…ç½®
BATCH_SIZE = 5  # æ¯æ‰¹å¤„ç†çš„æ–‡ä»¶æ•°é‡
DELAY_BETWEEN_REQUESTS = 1  # è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
BATCH_DELAY = 3  # æ‰¹æ¬¡é—´éš”ï¼ˆç§’ï¼‰

# é‡è¯•é…ç½®
MAX_RETRIES = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
RETRY_DELAY = 5  # é‡è¯•é—´éš”ï¼ˆç§’ï¼‰
API_TIMEOUT = 120  # APIè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

# å…¨å±€ç»Ÿè®¡å˜é‡
retry_stats = {
    'total_retries': 0,
    'timeout_errors': 0,
    'connection_errors': 0,
    'other_errors': 0
}

# ç³»ç»Ÿæç¤ºè¯
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å†…å®¹ç¼–è¾‘å’Œç¿»è¯‘ä¸“å®¶ã€‚è¯·å°†ç”¨æˆ·æä¾›çš„å­—å¹•è½¬æ¢ä¸ºæµç•…ã€è‡ªç„¶çš„ç®€ä½“ä¸­æ–‡æ–‡ç« ã€‚

è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹è¦æ±‚ï¼š
1. **å®Œæ•´è½¬æ¢**ï¼šå°†æ‰€æœ‰å†…å®¹è¿›è¡Œè½¬æ¢ï¼Œä¸é—æ¼ä»»ä½•å†…å®¹ï¼Œä¿ç•™æºæ–‡æ¡£æ‰€æœ‰å†…å®¹ä¿¡æ¯
2. **æ™ºèƒ½åˆ†æ®µ**ï¼šå°†å£è¯­åŒ–çš„çŸ­å¥åˆå¹¶æˆè‡ªç„¶çš„æ®µè½ï¼Œæ”¹å–„å¯è¯»æ€§
3. **ä¿æŒåŸæ„**ï¼šä¿æŒåŸå§‹å†…å®¹çš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§ï¼Œä¸æ·»åŠ æˆ–åˆ é™¤ä¿¡æ¯
4. **æ ¼å¼ä¼˜åŒ–**ï¼š
   - ä½¿ç”¨åˆé€‚çš„æ ‡é¢˜å’Œæ®µè½ç»“æ„
   - æ·»åŠ å¿…è¦çš„æ ‡ç‚¹ç¬¦å·
   - å»é™¤å£è¯­åŒ–çš„å†—ä½™è¯æ±‡ï¼ˆå¦‚"è¿™ä¸ª"ã€"é‚£ä¸ª"ç­‰è¿‡åº¦ä½¿ç”¨ï¼‰
5. **å†…å®¹ç»“æ„**ï¼š
   - å¼€å¤´éƒ¨åˆ†ï¼šå¼•è¨€æˆ–å¯¼å…¥éƒ¨åˆ†
   - ä¸»è¦å†…å®¹ï¼šæŒ‰é€»è¾‘åˆ†æ®µç»„ç»‡ï¼Œä¿æŒå†…å®¹çš„è¿è´¯æ€§
   - ç»“å°¾éƒ¨åˆ†ï¼šæ€»ç»“æˆ–ç»“è®º

ç›´æ¥è¾“å‡ºæ•´ç†åçš„æ–‡ç« å†…å®¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–æ ‡è®°ã€‚"""

def load_api_keys():
    """åŠ è½½APIå¯†é’¥åˆ—è¡¨"""
    try:
        with open(API_KEYS_FILE, 'r', encoding='utf-8') as f:
            keys = [line.strip() for line in f if line.strip()]
        return keys
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°APIå¯†é’¥æ–‡ä»¶ {API_KEYS_FILE}")
        return []

def save_api_keys(keys):
    """ä¿å­˜APIå¯†é’¥åˆ—è¡¨"""
    with open(API_KEYS_FILE, 'w', encoding='utf-8') as f:
        for key in keys:
            f.write(key + '\n')

def move_key_to_deprecated(api_key):
    """å°†æ— ç§¯åˆ†çš„APIå¯†é’¥ç§»åŠ¨åˆ°åºŸå¼ƒæ–‡ä»¶"""
    try:
        # è¯»å–ç°æœ‰çš„åºŸå¼ƒå¯†é’¥
        deprecated_keys = []
        if os.path.exists(DEPRECATED_KEYS_FILE):
            with open(DEPRECATED_KEYS_FILE, 'r', encoding='utf-8') as f:
                deprecated_keys = [line.strip() for line in f if line.strip()]
        
        # æ·»åŠ æ–°çš„åºŸå¼ƒå¯†é’¥
        if api_key not in deprecated_keys:
            deprecated_keys.append(api_key)
            with open(DEPRECATED_KEYS_FILE, 'w', encoding='utf-8') as f:
                for key in deprecated_keys:
                    f.write(key + '\n')
            print(f"ğŸ—‘ï¸  å·²å°†æ— ç§¯åˆ†çš„APIå¯†é’¥ç§»åŠ¨åˆ° {DEPRECATED_KEYS_FILE}")
    except Exception as e:
        print(f"âš ï¸  ç§»åŠ¨åºŸå¼ƒå¯†é’¥æ—¶å‡ºé”™: {e}")

def get_next_api_key():
    """è·å–ä¸‹ä¸€ä¸ªå¯ç”¨çš„APIå¯†é’¥"""
    global current_api_key
    
    api_keys = load_api_keys()
    if not api_keys:
        print("âŒ é”™è¯¯ï¼šæ²¡æœ‰å¯ç”¨çš„APIå¯†é’¥")
        return None
    
    current_api_key = api_keys[0]
    print(f"ğŸ”‘ ä½¿ç”¨APIå¯†é’¥: {current_api_key[:20]}...")
    return current_api_key

def switch_to_next_api_key():
    """åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªAPIå¯†é’¥"""
    global current_api_key
    
    api_keys = load_api_keys()
    if not api_keys:
        print("âŒ é”™è¯¯ï¼šæ²¡æœ‰å¯ç”¨çš„APIå¯†é’¥")
        return None
    
    if current_api_key and current_api_key in api_keys:
        # ç§»åŠ¨å½“å‰å¯†é’¥åˆ°åºŸå¼ƒæ–‡ä»¶
        move_key_to_deprecated(current_api_key)
        
        # ä»å¯ç”¨å¯†é’¥åˆ—è¡¨ä¸­ç§»é™¤
        api_keys.remove(current_api_key)
        save_api_keys(api_keys)
        
        print(f"ğŸ”„ APIå¯†é’¥ {current_api_key[:20]}... ç§¯åˆ†ä¸è¶³ï¼Œåˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ª")
    
    if api_keys:
        current_api_key = api_keys[0]
        print(f"ğŸ”‘ åˆ‡æ¢åˆ°æ–°çš„APIå¯†é’¥: {current_api_key[:20]}...")
        return current_api_key
    else:
        print("âŒ é”™è¯¯ï¼šæ‰€æœ‰APIå¯†é’¥éƒ½å·²ç”¨å®Œç§¯åˆ†")
        current_api_key = None
        return None

def call_linkai_api(messages, retry_count=0):
    """è°ƒç”¨LinkAI APIï¼Œå¸¦é‡è¯•æœºåˆ¶å’Œè‡ªåŠ¨å¯†é’¥åˆ‡æ¢"""
    global current_api_key
    
    # ç¡®ä¿æœ‰å¯ç”¨çš„APIå¯†é’¥
    if not current_api_key:
        current_api_key = get_next_api_key()
        if not current_api_key:
            return None
    
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {current_api_key}"
    }
    
    body = {
        "messages": messages,
        "stream": False,
        "temperature": 0.3,
        "model": "Gemini-2.0-flash"
    }
    
    for attempt in range(MAX_RETRIES):
        try:
            if attempt > 0:
                retry_stats['total_retries'] += 1
                print(f"    ğŸ”„ ç¬¬ {attempt + 1} æ¬¡é‡è¯•...")
                time.sleep(RETRY_DELAY)
            
            response = requests.post(CHAT_URL, json=body, headers=headers, timeout=API_TIMEOUT)
            
            if response.status_code == 200:
                result = response.json()
                if 'choices' in result and len(result['choices']) > 0:
                    if attempt > 0:
                        print(f"    âœ… é‡è¯•æˆåŠŸï¼")
                    return result['choices'][0]['message']['content']
                else:
                    print(f"    âŒ APIå“åº”æ ¼å¼å¼‚å¸¸: {result}")
                    if attempt == MAX_RETRIES - 1:
                        retry_stats['other_errors'] += 1
                        return None
                    continue
            elif response.status_code == 406:
                print(f"    ğŸ’³ APIå¯†é’¥ç§¯åˆ†ä¸è¶³ (406é”™è¯¯)")
                # åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªAPIå¯†é’¥
                new_key = switch_to_next_api_key()
                if new_key:
                    # æ›´æ–°è¯·æ±‚å¤´ä¸­çš„å¯†é’¥
                    headers["Authorization"] = f"Bearer {new_key}"
                    print(f"    ğŸ”„ å·²åˆ‡æ¢APIå¯†é’¥ï¼Œé‡æ–°å°è¯•...")
                    continue
                else:
                    print(f"    âŒ æ‰€æœ‰APIå¯†é’¥éƒ½å·²ç”¨å®Œç§¯åˆ†")
                    retry_stats['other_errors'] += 1
                    return None
            else:
                print(f"    âŒ APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                print(f"    é”™è¯¯ä¿¡æ¯: {response.text}")
                if attempt == MAX_RETRIES - 1:
                    retry_stats['other_errors'] += 1
                    return None
                continue
                
        except requests.exceptions.Timeout:
            retry_stats['timeout_errors'] += 1
            print(f"    â° APIè¶…æ—¶ (è¶…è¿‡{API_TIMEOUT}ç§’)")
            if attempt == MAX_RETRIES - 1:
                print(f"    âŒ å·²é‡è¯• {MAX_RETRIES} æ¬¡ï¼Œä»ç„¶è¶…æ—¶ï¼Œè·³è¿‡æ­¤æ–‡ä»¶")
                return None
            continue
        except requests.exceptions.ConnectionError:
            retry_stats['connection_errors'] += 1
            print(f"    ğŸŒ ç½‘ç»œè¿æ¥é”™è¯¯")
            if attempt == MAX_RETRIES - 1:
                print(f"    âŒ å·²é‡è¯• {MAX_RETRIES} æ¬¡ï¼Œä»ç„¶è¿æ¥å¤±è´¥ï¼Œè·³è¿‡æ­¤æ–‡ä»¶")
                return None
            continue
        except Exception as e:
            retry_stats['other_errors'] += 1
            print(f"    âŒ APIè°ƒç”¨å¼‚å¸¸: {e}")
            if attempt == MAX_RETRIES - 1:
                print(f"    âŒ å·²é‡è¯• {MAX_RETRIES} æ¬¡ï¼Œä»ç„¶å¤±è´¥ï¼Œè·³è¿‡æ­¤æ–‡ä»¶")
                return None
            continue
    
    return None

def process_text_with_ai(text, title, publish_date):
    """ä½¿ç”¨AIå¤„ç†æ–‡æœ¬ï¼Œè½¬æ¢ä¸ºé«˜è´¨é‡çš„ç®€ä½“ä¸­æ–‡æ–‡ç« """
    user_prompt = f"""è¯·å°†ä»¥ä¸‹è§†é¢‘å­—å¹•å†…å®¹è½¬æ¢ä¸ºé«˜è´¨é‡çš„ç®€ä½“ä¸­æ–‡æ–‡ç« ï¼š

æ ‡é¢˜ï¼š{title}
å‘å¸ƒæ—¶é—´ï¼š{publish_date}

å­—å¹•å†…å®¹ï¼š
{text}

è¯·æŒ‰ç…§è¦æ±‚è¾“å‡ºæ•´ç†åçš„æ–‡ç« å†…å®¹ã€‚"""

    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": user_prompt}
    ]
    
    return call_linkai_api(messages)

def extract_key_topics(title, content):
    """æå–å…³é”®ä¸»é¢˜"""
    topics = []
    
    # é€šç”¨ä¸»é¢˜å…³é”®è¯åˆ†ç±»
    topic_categories = {
        'ç§‘æŠ€': ['ç§‘æŠ€', 'æŠ€æœ¯', 'AI', 'äººå·¥æ™ºèƒ½', 'æœºå™¨äºº', 'è‡ªåŠ¨åŒ–', 'æ•°å­—åŒ–', 'äº’è”ç½‘', 'è½¯ä»¶', 'ç¡¬ä»¶', 'ç¼–ç¨‹', 'å¼€å‘'],
        'æ•™è‚²': ['æ•™è‚²', 'å­¦ä¹ ', 'åŸ¹è®­', 'è¯¾ç¨‹', 'æ•™å­¦', 'çŸ¥è¯†', 'æŠ€èƒ½', 'å­¦æ ¡', 'å¤§å­¦', 'è€ƒè¯•', 'å­¦æœ¯'],
        'ç”Ÿæ´»': ['ç”Ÿæ´»', 'æ—¥å¸¸', 'å®¶åº­', 'å¥åº·', 'ç¾é£Ÿ', 'æ—…è¡Œ', 'è¿åŠ¨', 'å¨±ä¹', 'æ—¶å°š', 'è´­ç‰©'],
        'å•†ä¸š': ['å•†ä¸š', 'åˆ›ä¸š', 'ä¼ä¸š', 'ç®¡ç†', 'è¥é”€', 'é”€å”®', 'å“ç‰Œ', 'å•†åŠ¡', 'åˆä½œ', 'å‘å±•'],
        'æŠ•èµ„ç†è´¢': ['æŠ•èµ„', 'ç†è´¢', 'é‡‘è', 'è‚¡ç¥¨', 'åŸºé‡‘', 'ä¿é™©', 'é“¶è¡Œ', 'ç»æµ', 'è´¢å¯Œ', 'èµ„äº§'],
        'èŒåœº': ['èŒåœº', 'å·¥ä½œ', 'æ±‚èŒ', 'ç®€å†', 'é¢è¯•', 'èŒä¸š', 'æ™‹å‡', 'æŠ€èƒ½', 'èƒ½åŠ›', 'ç»éªŒ'],
        'æ–‡åŒ–': ['æ–‡åŒ–', 'è‰ºæœ¯', 'å†å²', 'ä¼ ç»Ÿ', 'æ°‘ä¿—', 'éŸ³ä¹', 'ç”µå½±', 'ä¹¦ç±', 'æ–‡å­¦', 'å“²å­¦'],
        'å¥åº·åŒ»ç–—': ['å¥åº·', 'åŒ»ç–—', 'å…»ç”Ÿ', 'ç–¾ç—…', 'æ²»ç–—', 'è¯ç‰©', 'åŒ»é™¢', 'åŒ»ç”Ÿ', 'ä¿å¥', 'è¥å…»'],
        'æ–°é—»æ—¶äº‹': ['æ–°é—»', 'æ—¶äº‹', 'æ”¿æ²»', 'ç¤¾ä¼š', 'å›½é™…', 'æ”¿ç­–', 'æ³•å¾‹', 'ç¯å¢ƒ', 'æ°”å€™', 'äº‹ä»¶']
    }
    
    # æ£€æŸ¥æ ‡é¢˜å’Œå†…å®¹ä¸­çš„å…³é”®è¯
    text_to_check = (title + ' ' + content).lower()
    
    for category, keywords in topic_categories.items():
        if any(keyword.lower() in text_to_check for keyword in keywords):
            topics.append(category)
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•åˆ†ç±»ï¼Œæ ¹æ®å†…å®¹é•¿åº¦å’Œç‰¹å¾è‡ªåŠ¨åˆ†ç±»
    if not topics:
        if len(content) > 2000:
            topics.append('æ·±åº¦å†…å®¹')
        elif any(word in text_to_check for word in ['å¦‚ä½•', 'æ€ä¹ˆ', 'æ–¹æ³•', 'æŠ€å·§', 'æ•™ç¨‹']):
            topics.append('æ•™ç¨‹æŒ‡å—')
        elif any(word in text_to_check for word in ['åˆ†äº«', 'ç»éªŒ', 'å¿ƒå¾—', 'æ„Ÿå—', 'ä½“éªŒ']):
            topics.append('ç»éªŒåˆ†äº«')
        elif any(word in text_to_check for word in ['è¯„æµ‹', 'æµ‹è¯„', 'å¯¹æ¯”', 'æ¨è', 'é€‰æ‹©']):
            topics.append('è¯„æµ‹æ¨è')
        else:
            topics.append('ç»¼åˆå†…å®¹')
    
    return topics[:3]  # æœ€å¤šè¿”å›3ä¸ªä¸»é¢˜æ ‡ç­¾

def process_single_vtt_file(vtt_file_path):
    """å¤„ç†å•ä¸ªVTTæ–‡ä»¶"""
    try:
        filename = os.path.basename(vtt_file_path)
        print(f"ğŸ“ å¤„ç†: {filename}")
        
        # è§£æVTTæ–‡ä»¶
        result = parse_vtt_file(vtt_file_path)
        if not result or not result[0]:
            print(f"  âŒ VTTè§£æå¤±è´¥")
            return False
        
        text, timestamp_info = result
        
        # è·å–åŸºæœ¬ä¿¡æ¯
        title = timestamp_info.get('title', 'æœªçŸ¥æ ‡é¢˜') if timestamp_info else os.path.splitext(filename)[0]
        publish_date = timestamp_info.get('publish_date', 'æœªçŸ¥æ—¥æœŸ') if timestamp_info else 'æœªçŸ¥æ—¥æœŸ'
        
        # ä½¿ç”¨AIå¤„ç†å†…å®¹
        print(f"  ğŸ¤– è°ƒç”¨AIå¤„ç†å†…å®¹...")
        processed_content = process_text_with_ai(text, title, publish_date)
        
        if not processed_content:
            print(f"  âŒ AIå¤„ç†æœ€ç»ˆå¤±è´¥ï¼Œè·³è¿‡æ­¤æ–‡ä»¶")
            return False
        
        # æå–ä¸»é¢˜
        topics = extract_key_topics(title, processed_content)
        
        # ç”Ÿæˆæœ€ç»ˆçš„MDå†…å®¹
        md_content = f"""---
title: {title}
publish_date: {publish_date}
topics: {', '.join(topics)}
word_count: {len(processed_content)}
processed_by: LinkAI
processed_at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
---

# {title}

**å‘å¸ƒæ—¶é—´**: {publish_date}  
**ä¸»è¦è¯é¢˜**: {', '.join(topics)}

---

{processed_content}

---

*æœ¬æ–‡ç”±LinkAIæ™ºèƒ½åŠ©æ‰‹æ•´ç†å‘å¸ƒï¼Œå†…å®¹ä»…ä¾›å‚è€ƒ*
"""
        
        # ä¿å­˜MDæ–‡ä»¶
        md_filename = f"{os.path.splitext(filename)[0]}.md"
        md_file_path = os.path.join(MD_FOLDER, md_filename)
        
        with open(md_file_path, 'w', encoding='utf-8') as f:
            f.write(md_content)
        
        print(f"  âœ… å®Œæˆ: {len(processed_content)}å­—ç¬¦")
        return True
        
    except Exception as e:
        print(f"  âŒ å¤„ç†å‡ºé”™: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='VTTåˆ°Markdownæ‰¹é‡å¤„ç†å™¨')
    parser.add_argument('count', type=int, nargs='?', default=0, 
                       help='å¤„ç†æ–‡ä»¶æ•°é‡ï¼š0è¡¨ç¤ºå…¨éƒ¨ï¼Œå…¶ä»–æ•°å­—è¡¨ç¤ºå‰Nä¸ªæ–‡ä»¶')
    
    args = parser.parse_args()
    process_count = args.count
    
    # åˆå§‹åŒ–APIå¯†é’¥
    global current_api_key
    current_api_key = get_next_api_key()
    if not current_api_key:
        print("âŒ é”™è¯¯ï¼šæ²¡æœ‰å¯ç”¨çš„APIå¯†é’¥ï¼Œè¯·æ£€æŸ¥ api_keys.txt æ–‡ä»¶")
        return
    
    start_time = datetime.now()
    print("=== VTTåˆ°Markdownæ‰¹é‡å¤„ç†å™¨ ===")
    print(f"å¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"è¾“å…¥ç›®å½•: {VTT_FOLDER}")
    print(f"è¾“å‡ºç›®å½•: {MD_FOLDER}")
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(MD_FOLDER, exist_ok=True)
    
    # è·å–æ‰€æœ‰VTTæ–‡ä»¶
    vtt_files = glob.glob(os.path.join(VTT_FOLDER, "*.vtt"))
    print(f"æ‰¾åˆ° {len(vtt_files)} ä¸ªVTTæ–‡ä»¶")
    
    # æ£€æŸ¥å·²å¤„ç†çš„æ–‡ä»¶
    existing_md_files = set()
    if os.path.exists(MD_FOLDER):
        existing_md_files = set(os.path.splitext(f)[0] for f in os.listdir(MD_FOLDER) if f.endswith('.md'))
    
    # è¿‡æ»¤å‡ºæœªå¤„ç†çš„æ–‡ä»¶
    unprocessed_files = []
    for vtt_file in vtt_files:
        base_name = os.path.splitext(os.path.basename(vtt_file))[0]
        if base_name not in existing_md_files:
            unprocessed_files.append(vtt_file)
    
    print(f"éœ€è¦å¤„ç† {len(unprocessed_files)} ä¸ªæ–°æ–‡ä»¶")
    
    if not unprocessed_files:
        print("âœ… æ‰€æœ‰æ–‡ä»¶éƒ½å·²å¤„ç†å®Œæˆï¼")
        return
    
    # æ ¹æ®å‚æ•°ç¡®å®šå¤„ç†çš„æ–‡ä»¶
    if process_count == 0:
        files_to_process = unprocessed_files
        print(f"ğŸš€ å…¨é‡å¤„ç†æ¨¡å¼ï¼šå¤„ç†æ‰€æœ‰ {len(files_to_process)} ä¸ªæ–‡ä»¶")
    else:
        files_to_process = unprocessed_files[:process_count]
        print(f"ğŸ¯ é™é‡å¤„ç†æ¨¡å¼ï¼šå¤„ç†å‰ {len(files_to_process)} ä¸ªæ–‡ä»¶")
    
    # é¢„ä¼°æ—¶é—´
    estimated_time = len(files_to_process) * 20 / 60
    print(f"é¢„ä¼°å¤„ç†æ—¶é—´ï¼šçº¦ {estimated_time:.1f} åˆ†é’Ÿ")
    print(f"APIè°ƒç”¨æ¬¡æ•°ï¼š{len(files_to_process)} æ¬¡")
    
    # å¼€å§‹å¤„ç†
    print(f"\nğŸš€ å¼€å§‹å¤„ç†...")
    
    success_count = 0
    total_files = len(files_to_process)
    
    for i in range(0, total_files, BATCH_SIZE):
        batch_files = files_to_process[i:i+BATCH_SIZE]
        batch_num = i // BATCH_SIZE + 1
        total_batches = (total_files + BATCH_SIZE - 1) // BATCH_SIZE
        
        print(f"\nğŸ”„ æ‰¹æ¬¡ {batch_num}/{total_batches} (æ–‡ä»¶ {i+1}-{min(i+BATCH_SIZE, total_files)})")
        
        for j, vtt_file in enumerate(batch_files):
            if process_single_vtt_file(vtt_file):
                success_count += 1
            
            # è¯·æ±‚é—´éš”
            if j < len(batch_files) - 1:
                time.sleep(DELAY_BETWEEN_REQUESTS)
        
        # æ˜¾ç¤ºè¿›åº¦
        progress = (i + len(batch_files)) / total_files * 100
        elapsed_time = (datetime.now() - start_time).total_seconds() / 60
        print(f"  ğŸ“Š è¿›åº¦: {progress:.1f}% ({i + len(batch_files)}/{total_files}) | ç”¨æ—¶: {elapsed_time:.1f}åˆ†é’Ÿ")
        
        # æ‰¹æ¬¡é—´éš”
        if i + BATCH_SIZE < total_files:
            print(f"  ğŸ’¤ ä¼‘æ¯ {BATCH_DELAY} ç§’...")
            time.sleep(BATCH_DELAY)
    
    end_time = datetime.now()
    total_time = (end_time - start_time).total_seconds() / 60
    
    print(f"\n=== å¤„ç†å®Œæˆ ===")
    print(f"âœ… æˆåŠŸå¤„ç†: {success_count} ä¸ªæ–‡ä»¶")
    print(f"âŒ å¤„ç†å¤±è´¥: {total_files - success_count} ä¸ªæ–‡ä»¶")
    print(f"â±ï¸ æ€»ç”¨æ—¶: {total_time:.1f} åˆ†é’Ÿ")
    
    # æ˜¾ç¤ºé‡è¯•ç»Ÿè®¡
    if retry_stats['total_retries'] > 0:
        print(f"\nğŸ“Š é‡è¯•ç»Ÿè®¡:")
        print(f"  ğŸ”„ æ€»é‡è¯•æ¬¡æ•°: {retry_stats['total_retries']}")
        print(f"  â° è¶…æ—¶é”™è¯¯: {retry_stats['timeout_errors']}")
        print(f"  ğŸŒ è¿æ¥é”™è¯¯: {retry_stats['connection_errors']}")
        print(f"  â“ å…¶ä»–é”™è¯¯: {retry_stats['other_errors']}")
    else:
        print(f"ğŸ‰ æ‰€æœ‰APIè°ƒç”¨ä¸€æ¬¡æˆåŠŸï¼Œæ— éœ€é‡è¯•ï¼")
    
    print(f"\nğŸ“ è¾“å‡ºç›®å½•: {MD_FOLDER}")
    print(f"ç»“æŸæ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == "__main__":
    main()
